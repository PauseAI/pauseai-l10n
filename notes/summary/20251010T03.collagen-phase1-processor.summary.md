# Collagen Phase 1 Processor Implementation

**Date:** 2025-10-10
**Session:** Phase 1A webhook processor with dual-size storage
**GitHub Issue:** #3 (Phase 1A: Webhook-based Sync Implementation)
**Branch:** main

## What Was Built

Implemented complete EC2-based webhook processor for Cloudinary photo sync with dual-size storage strategy.

### Core Components

**Production Code (`scripts/`):**
- `processor.py` - Webhook processor with parallel downloads, EXIF embedding, dual-size generation
- `campaign_logger.py` - Campaign-specific persistent logging to EFS
- `webhook-receiver.py` - Flask app with signature validation (fixed SHA-1 + timestamp)
- Supporting: nginx config, systemd service, requirements.txt

**Infrastructure (`setup/`):**
- `setup-aws-infra.sh` - AWS resource provisioning
- `setup-ec2.sh` - EC2 instance configuration

**Tools (`tools/`):**
- `redrive_folder.py` - Redrive entire asset_folder (toggle M→pending→M)
- `toggle_test_image.py` / `reject_test_image.py` - Single image testing
- `optimize_grid_v3.py` - Grid layout optimizer for 4K collages
- Cloudinary inspection utilities (list, check formats, etc.)

**Benchmarks (`benchmarks/`):**
- Montage performance testing (synthetic and real photos)
- PNG vs JPEG collage generation
- EFS caching behavior validation
- Thumbnail generation timing

## Key Decisions

### Dual-Size Storage Strategy

**Problem:** Generating collages from 1500×2000 photos takes 2-3 minutes (unacceptable for HTTP).

**Solution:** Store two sizes per photo:
- **Archive:** `approved/photo.jpg` (1500×2000 JPEG, ~200KB) - original quality
- **Collage-ready:** `thumbnails/photo.png` (300×400 PNG, ~175KB) - pre-generated

**Results:**
- Collage generation: 35-49s for up to 1000 images ✓ (fits HTTP timeout)
- Webhook overhead: +0.2s per photo (acceptable)
- Quality: No perceptible difference in final 4K collages
- Memory: 48MB for 999 images (works on t3.micro)

### Format Normalization

**Decision:** Always download as JPG via Cloudinary's `f_jpg` transformation.

**Rationale:**
- Handles HEIC, PNG, WEBP (converts all to JPG)
- Simplifies EXIF embedding (JPG only)
- ImageMagick compatibility guaranteed
- 99.2% of images already JPG

### Email Sanitization for Testing

**Problem:** test_prototype contains real email addresses.

**Solution:** For `asset_folder=test_prototype`, transform emails:
- `user@example.com` → `collagen-test+user-example-com@antb.me`
- Prevents accidental emails to real users
- Emails route to Anthony's domain for testing

### Grid Optimization Algorithm

**Problem:** How to fit N 3:4 portrait images into 4096×4096 square collage?

**Solution:** Smart search algorithm exploring:
- Image counts k ≤ n (omitting images is acceptable)
- Grid factorizations where cols/rows ≈ 4/3 (for square output)
- Cell sizes (3k)×(4k) for exact 3:4 aspect ratio
- Strategies: pad both, clip one axis, clip both

**Cost model:**
- Empty grid slots: 100,000 per slot (very bad)
- Omitted images: 1,500 × (k/n)
- Padding: 1.0 per pixel
- Clipping: 2.0 per pixel (worse than padding)
- Max clipping: 33% of edge cell

**Results for key counts:**
- 229 images: 17×13 grid, 237×316 cells (omit 8, +34px H pad, -6px V clip per edge)
- 1000 images: 36×27 grid, 114×152 cells (omit 28, -4px both edges)

### Webhook Signature Validation

**Issue:** Initial implementation used wrong algorithm.

**Fix:** Cloudinary signs with: `SHA1(body + X-Cld-Timestamp + api_secret)`

**Not:** `HMAC-SHA256(body, secret)`

Tested and verified working (invalid signatures rejected with 401).

### Architecture: EC2 Direct (Not Lambda)

**Deviation from Issue #3:** Implemented EC2 Flask receiver instead of API Gateway→SQS→Lambda.

**Rationale:**
- Faster iteration during development
- Simpler debugging
- Phase 0 infrastructure already had EC2 + EFS
- API Gateway migration deferred to Phase 2 (separate concern from core processor logic)

**Trade-off:**
- Risk: Lost webhooks if EC2 down during Cloudinary's 9-min retry window
- Acceptable for Phase 1 testing with test_prototype

## Technical Implementation Details

### Processor Workflow

**Approved webhook:**
1. Parallel: Cloudinary API (metadata) + CDN (image bytes) → both to `/tmp/`
2. Check `asset_folder` (from API, not public_id prefix)
3. Filter: only process `test_prototype` in Phase 1
4. Embed email in EXIF UserComment (sanitized for test campaigns)
5. Save full JPEG to `approved/`
6. Generate 300×400 PNG thumbnail to `thumbnails/`
7. Log to campaign-specific `processor.log`

**Rejected webhook:**
- Delete both `approved/*.jpg` and `thumbnails/*.png`

**Pending webhook:**
- Ignore (limbo state, not a rejection)

### Path Conventions

Helper method `thumb_for_approved(path)` enforces single source of truth:
- `approved/photo.jpg` → `thumbnails/photo.png` (file)
- `campaign/approved/` → `campaign/thumbnails/` (directory)

Clients never hardcode thumbnail paths - always derive from approved path.

### Performance Characteristics

**On t3.micro (1GB RAM, 2 vCPU):**

| Operation | 221 images | 999 images |
|-----------|------------|------------|
| From 1500×2000 sources | 60s | 163s (too slow) |
| From 300×400 thumbnails | 35s ✓ | 49s ✓ |
| Memory | 48MB | 48MB |

**NFS caching:** Photos written via webhook stay in Linux page cache (700MB free RAM). Collage generation reads are cached (negligible network overhead).

## Current Status

**Completed:**
- ✅ EC2 webhook receiver with signature validation
- ✅ Dual-size storage (JPEG + PNG)
- ✅ Campaign filtering (test_prototype only)
- ✅ Email sanitization for test campaigns
- ✅ Format normalization (always JPG)
- ✅ Redrive mechanism for backfills
- ✅ Grid optimization algorithm
- ✅ Performance benchmarking

**Test Data:**
- 20 images in test_prototype asset_folder (all approved)
- All synced to `/mnt/efs/test_prototype/approved/` + `/thumbnails/`
- EXIF contains sanitized emails

**Deferred to Phase 2:**
- API Gateway + SQS + Lambda migration
- Production (sayno) enablement
- Collage generation web UI
- Email sending

## Next Steps (Revised Plan)

### Phase 2A: AWS Infrastructure Migration
- API Gateway → SQS → EC2 processor (not Lambda - EFS already mounted)
- Enable sayno campaign processing
- Redrive sayno folder (backfill 229 approved images)

### Phase 2B: Collage Generation Web App
- Admin UI for generating collages
- Reuse `optimize_grid_v3.py` for layout selection
- Two-step montage: thumbnails → PNG master → JPEG derivatives
- Preview before publish

### Phase 3: Email Notification
- Dry-run mode (logs but doesn't send)
- Allowlist for testing (specific pauseai.info addresses)
- Integration with pauseai-website (display published collages)
- Production rollout (phased: small test group → full 229 users)

### MVP: Production-Ready
- Monitoring and alerts
- AWS Backup for EFS
- Documentation
- Handoff to team

## Key Learnings

### 1. Pre-Generated Thumbnails Are Essential

CPU-bound resize operations dominate processing time. Pre-generating 300×400 intermediates on webhook (~0.2s) makes collage generation synchronous (35-49s vs 60-163s).

### 2. Format Normalization Simplifies Everything

Always using `/f_jpg/` from Cloudinary eliminates format detection, branching, and edge cases. Quality loss from PNG→JPG conversion is imperceptible in collage context.

### 3. NFS Caching Works Well

Linux page cache keeps recently-written EFS files in RAM indefinitely (with 700MB free). Production workflow (write via webhook over time, read for collage) benefits fully from caching. No fscache disk-backed cache needed for current scale.

### 4. Grid Optimization Needs Smart Search

Brute-force grid search (6,400 configs) → smart factorization search (30-40 configs) exploring only grids close to 4:3 cols/rows ratio and cell sizes that don't exceed 33% clipping.

### 5. `public_id` Prefix Unreliable for Campaign

Images can be moved between folders (public_id changes, asset_folder doesn't). Always use `asset_folder` from Cloudinary API, never parse from `public_id`.

### 6. Pending ≠ Rejected

Pending is a limbo state (not yet moderated), not an explicit rejection. Only delete on `moderation_status='rejected'`, ignore pending webhooks.

## Configuration

### Environment Variables
```bash
CLOUDINARY_CLOUD_NAME=dyjlw1syg
CLOUDINARY_API_KEY=779717836612829
CLOUDINARY_API_SECRET=<from Psono>
GMAIL_APP_PASSWORD=<for testing email functionality>
```

### EFS Structure
```
/mnt/efs/
├── test_prototype/
│   ├── approved/           # 1500×2000 JPEG archive
│   ├── thumbnails/         # 300×400 PNG collage-ready
│   └── logs/
│       ├── processor.log   # Main events (SYNCED/DELETED/ERROR)
│       └── webhooks/       # Raw webhook payloads (not implemented yet)
└── sayno/                  # Production (Phase 2)
    └── [same structure]
```

### Python Environment
- Python 3.10.12 (matches EC2)
- pyenv for version management
- venv for isolation

## Testing Notes

### Redrive Mechanism
```bash
./venv/bin/python3 tools/redrive_folder.py test_prototype
```
Toggles all images M→pending→M to re-trigger webhooks. Safe to run multiple times (overwrites existing files).

### Grid Optimizer
```bash
./venv/bin/python3 tools/optimize_grid_v3.py
# Edit OMIT_BASE_COST, PAD_COST, CLIP_COST at top of file
```

### Benchmarks
Run on EC2 to test realistic conditions (NFS-mounted EFS, limited RAM).

## References

- Issue #3: Phase 1A implementation
- CLAUDE.md: Architecture and status
- ORIGINAL_PROJECT_PLAN.md: Original vision
- Bootstrap session (#500): Initial 142-user collage
